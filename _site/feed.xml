<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-01-14T11:35:51+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">5 Minute Cloud</title><subtitle>Healthcare Cloud Technology
</subtitle><author><name>Pete Wood</name><email>pete@fiveminute.cloud</email></author><entry><title type="html">Creating a Cost of Care prediction with TensorFlow</title><link href="http://localhost:4000/2021/01/11/Creating-a-Cost-of-Care-Prediction-with-TensorFlow.html" rel="alternate" type="text/html" title="Creating a Cost of Care prediction with TensorFlow" /><published>2021-01-11T00:00:00+00:00</published><updated>2021-01-11T00:00:00+00:00</updated><id>http://localhost:4000/2021/01/11/Creating-a-Cost-of-Care-Prediction-with-TensorFlow</id><content type="html" xml:base="http://localhost:4000/2021/01/11/Creating-a-Cost-of-Care-Prediction-with-TensorFlow.html">&lt;p&gt;I speak to a lot of people about AI. About the possibilities for healthcare, the limitations, the tools, and how the Cloud providers help us quickly build models. I decided to explore what it takes to build, train and publish a simple AI model to predict a patient’s insurance charges. In this 5 minute video, I explore how to create a simple ‘cost of care’ prediction model and gain experience with &lt;a href=&quot;https://to.fiveminute.cloud/1r2xMz&quot;&gt;TensorFlow&lt;/a&gt;, Google’s open source software library for machine learning with particular focus on training of deep neural networks. I decided to explore the steps that it takes to go from zero to a fully trained published model. In this 5 minute video I’ll show you the steps I had to take to create a blueprint for further investigation.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/6Zinxztsy5c&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;hello-world-with-tensorflow&quot;&gt;Hello World with TensorFlow&lt;/h1&gt;
&lt;p&gt;This adventure is very much a simple ‘Hello World’ example with TensorFlow and Python. I’ll use the following open source tools and you can read more about each of them by following the links:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.docker.com/products/docker-desktop&quot;&gt;Docker&lt;/a&gt; for the sandpit environment. I’m using version 3.0.3, but any recent version should be fine.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jupyterlab.readthedocs.io/en/stable/index.html&quot;&gt;Jupyter Lab&lt;/a&gt; for Python coding&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/&quot;&gt;Scikit-Learn&lt;/a&gt; for data normalization&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://matplotlib.org&quot;&gt;Matplotlib&lt;/a&gt; and &lt;a href=&quot;https://seaborn.pydata.org&quot;&gt;Seaborn&lt;/a&gt; for visualisation&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.tensorflow.org&quot;&gt;TensorFlow&lt;/a&gt; for linear regression machine learning algorithm&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://flask.palletsprojects.com/en/1.1.x/&quot;&gt;Flask&lt;/a&gt; for publishing the API.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These libraries will all be installed into the Docker container, which will be a quick sandpit environment.  I will build the  model in four simple steps:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Step 1 - Build a TensorFlow sandpit environment&lt;/li&gt;
  &lt;li&gt;Step 2 - Setup the Jupyter notebook&lt;/li&gt;
  &lt;li&gt;Step 3 - Build and train the machine learning model using linear regression&lt;/li&gt;
  &lt;li&gt;Step 4 - Publish the prediction model through an API using Flask&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;requirements-and-using-the-code-from-github&quot;&gt;Requirements and using the code from GitHub&lt;/h2&gt;
&lt;p&gt;If you’re following along, the only thing you’ll need installed is Docker, and code can be downloaded from &lt;a href=&quot;https://to.fiveminute.cloud/ekxWeR&quot;&gt;GitHub&lt;/a&gt;. On GitHub you’ll see a number of helper commands to help things run smoothly.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;build&lt;/em&gt; contains the command to build the Docker container from the &lt;a href=&quot;https://github.com/fiveminutecloud/fmctensorflow/blob/main/Dockerfile&quot;&gt;Dockerfile&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;run&lt;/em&gt; contains the commands to run our container, and also display the logs.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;cleanup&lt;/em&gt; will stop and delete the Docker container.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;logs&lt;/em&gt; will show the log files of the running container.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can copy the contents of GitHub to your local machine by running the &lt;a href=&quot;https://git-scm.com/downloads&quot;&gt;git&lt;/a&gt; command.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/fiveminutecloud/fmctensorflow.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;step-1---create-the-sandpit-environment&quot;&gt;Step 1 - Create the sandpit environment&lt;/h2&gt;
&lt;p&gt;Now, there are a few ways you can get a sandpit environment.  You can use something like AWS SageMaker, Azure Machine Learning, or Google Colab, but for this adventure i’ll quickly make my own local environment. This helps  understand a little more about what’s going on, but is also means I can use data sets which I might not be comfortable with sharing on the Cloud.&lt;/p&gt;

&lt;p&gt;My Dockerfile uses the standard python 3.7 base image from DockerHub, on which I layer Jupyter Lab, the TensorFlow machine learning libraries and the Flask libraries to publish the API.&lt;/p&gt;

&lt;div class=&quot;language-docker highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; python:3.7-slim&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;apt-get update
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;scikit-learn&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;0.23.2
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;jupyterlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;2.2.9
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;matplotlib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;3.3.3
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;seaborn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;0.11.0
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;1.18.5
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;2.3.1
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;flask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;1.1.2
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [&quot;jupyter-lab&quot;, &quot;--ip=0.0.0.0&quot;, &quot;--allow-root&quot;, &quot;--notebook-dir=/notebooks&quot;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Build the Docker container using the command&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker build &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; fmctensorflow &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;step-2---setup-the-jupyter-notebook&quot;&gt;Step 2 - Setup the Jupyter Notebook&lt;/h2&gt;
&lt;p&gt;Now I have a container image, I run it with the following command. This command creates an instance of the container, and opens two ports on the container. Port 8888 is opened so I can access Jupyter Notebooks through the web browser, and port 5000 is opened for the API which I’ll create shortly.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/notebooks:/notebooks &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; fmctensorflow &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 8888:8888 &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 5000:5000 fmctensorflow:latest
docker logs &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; fmctensorflow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Within the logs, there is a line which looks something like the line below. It contains the access token for the running instance of Jupyter, so I need that safely noted down. Simply copy the whole line into the browser, to access the Notebook. I recommend using the last link which starts http://127.0.0.1.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    To access the notebook, open this file in a browser:
        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html
    Or copy and paste one of these URLs:
        http://046ef7394882:8888/?token=9e976aecfb63ee81434e0272b4e996c130833ee891c91434e0272b4eaea6304e976aea8
     or http://127.0.0.1:8888/?token=e976aecfb63ee81434e0272b4e996c130833ee891c91434e0272b4eaea6304e976aea8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now in the web browser, I see &lt;em&gt;Launcher&lt;/em&gt; and click the Python3 logo to create a new Notebook.  You can right-click the file created on the left to rename it. 
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../../../assets/myimages/2021-01-12-17-39-42.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;step-3---build-and-train-the-tensorflow-model&quot;&gt;Step 3 - Build and train the TensorFlow model&lt;/h2&gt;
&lt;p&gt;You can view the actual Notebook &lt;a href=&quot;https://github.com/fiveminutecloud/fmctensorflow/blob/main/notebooks/fmctensorflow.ipynb&quot;&gt;here&lt;/a&gt;, but I’m going to summarize the eleven key steps below.&lt;/p&gt;

&lt;h3 id=&quot;a-import-the-libraries&quot;&gt;a. Import the libraries&lt;/h3&gt;
&lt;p&gt;Here I import the libraries that were layered into the Docker container during step 1. You’ll notice I’m using some libraries which I didn’t explicitly include (eg. Pandas), but we can still use them because they are part of the base Python 3.7 container.&lt;/p&gt;

&lt;h3 id=&quot;b-retrieve-the-data-set-for-training&quot;&gt;b. Retrieve the data set for training&lt;/h3&gt;
&lt;p&gt;The dataset I use for training is a public dataset from &lt;a href=&quot;https://www.kaggle.com/mirichoi0218/insurance/home&quot;&gt;Kaggle&lt;/a&gt; with a small sample of USA population medical insurance costs. It has 1338 records, with columns as follows:
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Feature&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
      &lt;th&gt;Type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Age&lt;/td&gt;
      &lt;td&gt;Patient age&lt;/td&gt;
      &lt;td&gt;Numeric&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sex&lt;/td&gt;
      &lt;td&gt;Patient sex&lt;/td&gt;
      &lt;td&gt;Text&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;BMI&lt;/td&gt;
      &lt;td&gt;Patient body-mass index&lt;/td&gt;
      &lt;td&gt;Numeric&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Children&lt;/td&gt;
      &lt;td&gt;Number of children&lt;/td&gt;
      &lt;td&gt;Numeric&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Smoker&lt;/td&gt;
      &lt;td&gt;Is the patient a smoker?&lt;/td&gt;
      &lt;td&gt;Text&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Region&lt;/td&gt;
      &lt;td&gt;Patient’s home region&lt;/td&gt;
      &lt;td&gt;Text&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Charges&lt;/td&gt;
      &lt;td&gt;Insurance costs&lt;/td&gt;
      &lt;td&gt;Numeric&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;c-visualise-and-explore-the-data-with-matplotlib&quot;&gt;c. Visualise and explore the data with Matplotlib&lt;/h3&gt;
&lt;p&gt;I am interested to understand the relationship between age and insurance costs. The following chart shows the distribution. Here I can see at least three linear relationships, so in the next step I’d like to understand the features that influence the insurance costs.
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../../../assets/myimages/2021-01-13-13-20-06.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;d-map-the-textual-values-to-numerical-values&quot;&gt;d. Map the textual values to numerical values&lt;/h3&gt;
&lt;p&gt;In order to understand the features that influence insurance costs, I need to delve deeper into the data. We’d like to look at creating a &lt;em&gt;correlation matrix&lt;/em&gt; to show how the costs change, as the features change. For example, do insurance costs go up as BMI increases?  How do the costs vary by region? 
In order to do this analysis, I use a &lt;em&gt;Correlation&lt;/em&gt; function, but it only works with numeric data.  Therefore, I create three mapping functions to map Sex, Smoker and Region to numeric values, so I configure the following mappings. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Feature&lt;/th&gt;
      &lt;th&gt;Text Values&lt;/th&gt;
      &lt;th&gt;Numeric Values&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Sex&lt;/td&gt;
      &lt;td&gt;male, female, undefined&lt;/td&gt;
      &lt;td&gt;0, 1, -1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Smoker&lt;/td&gt;
      &lt;td&gt;no, yes, undefined&lt;/td&gt;
      &lt;td&gt;0, 1, -1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Region&lt;/td&gt;
      &lt;td&gt;southwest,southeast,northwest,northeast, undefined&lt;/td&gt;
      &lt;td&gt;1, 2, 3, 4, 0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;e-look-at-the-correlation-between-data-items-with-pandas-and-seaborn&quot;&gt;e. Look at the &lt;em&gt;correlation&lt;/em&gt; between data items with Pandas and SeaBorn&lt;/h3&gt;
&lt;p&gt;I use &lt;em&gt;Pandas&lt;/em&gt; to first create the Correlation matrix, and then I use &lt;em&gt;SeaBorn&lt;/em&gt; to visualise the matrix to see the hotspots. From the charts below, I see the factors influencing the insurance costs are smoker, and then age. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;../../../assets/myimages/2021-01-13-13-41-01.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;../../../assets/myimages/Sex.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;f-separate-the-smokers-from-the-nonsmokers&quot;&gt;f. Separate the Smokers from the Nonsmokers&lt;/h3&gt;
&lt;p&gt;Since Smokers is a ‘yes/no’ value, in the next step I split the source data into Smokers and Nonsmokers so I can see the different trends. In the image below I can see the split of smokers and nonsmokers. I can see at least 3 linear relationships. I can see two for smokers (in grey), and a good linear relationship for nonsmokers (in blue) but with a sizable set of anomalies. So, for the rest of this example I’ll focus on the nonsmokers only. 
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../../../assets/myimages/2021-01-13-13-48-36.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;g-look-at-the-correlation-between-features-for-only-nonsmokers&quot;&gt;g. Look at the correlation between features for only Nonsmokers&lt;/h3&gt;
&lt;p&gt;Now, I re-run the Correlation function for nonsmokers only, and discover that age (unsurprisingly!) becomes the most significant factor in insurance charges.
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../../../assets/myimages/2021-01-13-13-54-06.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;h-normalize-the-input-values-with-scikit-learn&quot;&gt;h. Normalize the input values with Scikit-Learn&lt;/h3&gt;
&lt;p&gt;I now need to prepare the data for training.  It is best practice to normalize the input values, and I do this by creating a &lt;em&gt;scaler&lt;/em&gt;.  The scaler is a function that condenses the input dataset (age) down to a unit range (between 0-1). If you don’t do this, you may find your modeling fit &lt;a href=&quot;https://machinelearningmastery.com/exploding-gradients-in-neural-networks/&quot;&gt;&lt;em&gt;explodes&lt;/em&gt;&lt;/a&gt;. You don’t need to normalize the output values (costs).
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../../../assets/myimages/2021-01-13-13-56-33.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;i-split-the-data-into-a-training-and-testing-dataset&quot;&gt;i. Split the data into a training and testing dataset&lt;/h3&gt;
&lt;p&gt;There is one last thing needed before training the model. In step 3b, I noted we have 1338 records in our data set, of which 1064 are nonsmokers. I want to use most of the data for training the model. But, I also want to hold back some data so we can test the model afterwards and compare the predicted result with the actual result already known.  This helps understand the accuracy of our model. I decide to train the model on 1010 (95%) nonsmokers, and hold back 54 records for testing later.&lt;/p&gt;

&lt;h3 id=&quot;j-train-the-model-with-tensorflow&quot;&gt;j. Train the model with TensorFlow&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Finally!&lt;/em&gt; Eleven steps later, I can train our model with TensorFlow. TensorFlow works by creating &lt;em&gt;models&lt;/em&gt; and &lt;em&gt;layers&lt;/em&gt;. Models are made up of layers, and layers are the &lt;em&gt;functions&lt;/em&gt; containing the mathematical function. The power of TensorFlow allows you to build complex networks with multiple layers leading to very sophisticated prediction models. We will only create one &lt;a href=&quot;https://keras.io&quot;&gt;Keras&lt;/a&gt; layer.  The model fitting process is essentially &lt;em&gt;random&lt;/em&gt;.  And if you run the fitting process multiple times, you’ll get different results, unless you set the &lt;a href=&quot;https://machinelearningmastery.com/reproducible-results-neural-networks-keras/&quot;&gt;seed&lt;/a&gt; for the random number generator. Fitting basically selects a random position, and tests the training data against it.  It uses &lt;em&gt;Optimizers&lt;/em&gt; to determine the accuracy (or ‘loss’) of the prediction against the known outcome in the training set and adjusts the random position accordingly.  It’s like guessing a number between 1 and 100. You guess 50, I say lower. You guess 25, I say higher. Eventually you guess correctly. Sometimes you get lucky and it only takes a few guesses, other times it takes longer.  Each guess is called an &lt;em&gt;Epoch&lt;/em&gt;, and the more guesses you have the longer it takes, and the better the result. I’m using just 1000 epochs here. I’m only using 1064 records to train our model, and it works just fine locally. But what if you have millions, or billions of records. Well, TensorFlow scales crazy-well, and lots of the cloud providers, but especially &lt;a href=&quot;https://towardsdatascience.com/multi-worker-distributed-tensorflow-training-on-google-cloud-ai-platform-64b383341dd8&quot;&gt;Google Cloud AI&lt;/a&gt; support TensorFlow at scale. All this work allows us to run just three commands to train the model.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sgd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mean_squared_error'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I wait a few minutes for the modelling to run, and what do I get for my trouble? I get an &lt;em&gt;in memory&lt;/em&gt; model that can be used for predictions. But first, let’s evaluate the model against the 54 records held back in step 3i. I need to check the model makes reasonable predictions.&lt;/p&gt;

&lt;h3 id=&quot;k-evaluate-the-model-with-the-remaining-data-set&quot;&gt;k. Evaluate the model with the remaining data set&lt;/h3&gt;
&lt;p&gt;In this step I evaluate the model against the 54 records I held back.  I already know the insurance costs for these patients, so let’s see what the new prediction model gives. The green-dots show the actual costs recorded in the source data, but the red-crosses show the predicted costs. And it’s not too bad! Clearly, the test data has some anomalies, but remember in step 3g I choose to only focus on the patients &lt;em&gt;age&lt;/em&gt;.  I haven’t accounted for other features such as number of children, or BMI which may explain these deviations.&lt;/p&gt;

&lt;p&gt;You may also notice that the &lt;em&gt;age&lt;/em&gt; axis is still normalized because my model was trained on normalized &lt;em&gt;age&lt;/em&gt; data. In the final step 4,  you’ll see how I publish the model as an API, and use the &lt;em&gt;Scaler&lt;/em&gt; from step 3h to normalize the age for which I want the insurance cost prediction. 
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../../../assets/myimages/2021-01-13-15-53-41.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;step-4---deploy-the-model-as-an-api-with-flask&quot;&gt;Step 4 - Deploy the model as an API with Flask&lt;/h2&gt;
&lt;p&gt;I use the in-memory model created above, and create a web API around it so it can be used by mobile and web apps. I use Flask to create the API infrastructure, with one simple GET endpoint &lt;em&gt;predict&lt;/em&gt;, that takes &lt;em&gt;age&lt;/em&gt; as a single input value. When the container was started above in step 2, I opened port 5000 so we can access the Flask API though our web browser. I can now access the insurance cost predictor through one simple endpoint.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://localhost:5000/predict?age=45
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Remember, I said above the model works on a &lt;em&gt;normalized&lt;/em&gt; age value, so I simply use the same scaler from step 3h we created before to scale the age.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;scaler_input_array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;scaled_age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mm_scaler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaler_input_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;cost_prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaled_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I then pass the &lt;em&gt;normalized&lt;/em&gt; age to the model predictor and return the insurance cost in the HTTP response.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../../../assets/myimages/2021-01-12-18-32-30.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;if-you-run-into-problems&quot;&gt;If you run into problems&lt;/h2&gt;
&lt;p&gt;I like testing ideas in a isolated container because it provides a nice clean working space with known dependencies. If you’re following along with this ‘Hello World’ example and you run into difficulties, you can simply hit &lt;em&gt;reset&lt;/em&gt; and start again from a known state. The container can be restarted by running the &lt;em&gt;cleanup&lt;/em&gt; commands:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker &lt;span class=&quot;nb&quot;&gt;kill &lt;/span&gt;fmctensorflow
docker &lt;span class=&quot;nb&quot;&gt;rm &lt;/span&gt;fmctensorflow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You can then restart the container using the commands in step 2.&lt;/p&gt;

&lt;p&gt;If you have any other difficulties, please comment below.&lt;/p&gt;</content><author><name>Pete Wood</name><email>pete@fiveminute.cloud</email></author><category term="healthcare" /><category term="cloud" /><summary type="html">I speak to a lot of people about AI. About the possibilities for healthcare, the limitations, the tools, and how the Cloud providers help us quickly build models. I decided to explore what it takes to build, train and publish a simple AI model to predict a patient’s insurance charges. In this 5 minute video, I explore how to create a simple ‘cost of care’ prediction model and gain experience with TensorFlow, Google’s open source software library for machine learning with particular focus on training of deep neural networks. I decided to explore the steps that it takes to go from zero to a fully trained published model. In this 5 minute video I’ll show you the steps I had to take to create a blueprint for further investigation.</summary></entry><entry><title type="html">Five Healthcare Predictions for 2021</title><link href="http://localhost:4000/2021/01/04/Five-Healthcare-Predictions-for-2021.html" rel="alternate" type="text/html" title="Five Healthcare Predictions for 2021" /><published>2021-01-04T00:00:00+00:00</published><updated>2021-01-04T00:00:00+00:00</updated><id>http://localhost:4000/2021/01/04/Five-Healthcare-Predictions-for-2021</id><content type="html" xml:base="http://localhost:4000/2021/01/04/Five-Healthcare-Predictions-for-2021.html">&lt;p&gt;Today is a momentous occasion.  At 7.30GMT, the retired maintenance manager Brian Pinker, 82, became the first patient to receive the Oxford-AstraZeneca vaccine.  The first vaccine that doesn’t require super-cold storage. The ‘2020 BC epoch’, as I like to call it (Before-COVID), showed how predictions are often wildly inaccurate, and subject to different realities yet to be imagined. But, in a 2021 AC era (After-COVID), with vaccines being rolled out across the UK, I feel confident enough to make a few predictions about what the rest of 2021 has install for us.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/myimages/2021predictions.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My only disclaimer is these are my thoughts, and I reserve the right to change them. But, perhaps, just perhaps, you might be bold enough to wager a few Bitcoins that I might indeed be right.  Bitcoin is currently trading at a record high of $33,562 so my first prediction is it will only go down. Sorry about that.  But with that disclaimer out of the way, here are my top ideas for 2021 AC.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;prediction-1---telemedicine--remote-care-will-be-rehabilitated&quot;&gt;Prediction 1 - Telemedicine &amp;amp; remote care will be rehabilitated.&lt;/h3&gt;
&lt;p&gt;I’m currently receiving physiotherapy on a strained hip flexor muscle. Treatment before 2020 BC would have required me to book time off work, drive to the clinic, find a parking spot, sit in the waiting room, attend my session, drive home… you get the picture.  But, in a 2021 AC era, I have a 20-minute call at my convenience with the physio. She talk’s me through the exercises whilst I roam around the lounge stretching and panting through a headset. My wife (now working from home) looks at me quizzically.  I open the Physio App I’m subscribed to and watch the short videos elegantly demonstrating how the exercise is actually supposed to look.  It’s not pretty.  A moment later, I tick-off the exercise and it gets logged in my medical record that I am a good, compliant patient. The following morning, I receive an 8am reminder on my phone to repeat the exercises which I dutifully do.  Up until 2020, I would have felt short-changed with this kind of affair. I’m sure University students feel the same about remote learning, but that’s a whole different topic.&lt;/p&gt;

&lt;p&gt;The prediction is that remote care will finally feel normal and will start to gain traction in the health service, and these services will become more specialised.  The app I use for physiotherapy is wonderful for MSK issues, but it wouldn’t work for Diabetes, or other treatment paths. For as long as I can remember, remote care seemed weird, impersonal, pointless even, but remote care will be rehabilitated in 2021.  Services and software vendors that support remote care will boom in 2021, as patients accept it as normal, perhaps even more convenient. &lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Care providers have been eager to move to remote care because of the proven benefits like quality and safety, together with cost reduction.
&lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Companies I predict to boom include device manufacturers such as Honeywell, Medtronic, Abbot Labs, Baxtor International,  treatment platforms such as &lt;a href=&quot;https://to.fiveminute.cloud/NNO61h&quot;&gt;Virta Health&lt;/a&gt; and &lt;a href=&quot;https://to.fiveminute.cloud/khmm2E&quot;&gt;DrChrono&lt;/a&gt;, and personal data aggregators such as &lt;a href=&quot;https://to.fiveminute.cloud/UqHiJn&quot;&gt;Validic&lt;/a&gt; and &lt;a href=&quot;https://to.fiveminute.cloud/b7HGLB&quot;&gt;Envision2bWell&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;prediction-2--cloud-giants-will-expand-their-healthcare-ecosystems&quot;&gt;Prediction 2 – Cloud giants will expand their Healthcare ecosystems.&lt;/h3&gt;
&lt;p&gt;2020 saw the big cloud providers take a giant leap with their Healthcare platforms.  In November, Google &lt;a href=&quot;https://to.fiveminute.cloud/GfPhaJ&quot;&gt;unveiled&lt;/a&gt; its Healthcare Interoperability Readiness Programme. In December AWS &lt;a href=&quot;https://to.fiveminute.cloud/hOSpkG&quot;&gt;launched&lt;/a&gt; it’s ‘FHIR Works on AWS’ offering and &lt;a href=&quot;https://to.fiveminute.cloud/8SKwRM&quot;&gt;sprang&lt;/a&gt; the Amazon HealthLake.  Earlier in the year Redmond &lt;a href=&quot;https://to.fiveminute.cloud/xE8xrv&quot;&gt;showcased&lt;/a&gt; Microsoft Cloud for Healthcare and &lt;a href=&quot;https://to.fiveminute.cloud/qcdocv&quot;&gt;introduced&lt;/a&gt; the world to Azure IoT Connector, Azure API for FHIR and a &lt;a href=&quot;https://to.fiveminute.cloud/WCQrtb&quot;&gt;slew&lt;/a&gt; of other interoperability tools. Early April saw a shake-up at IBM with Arvind Krishna taking the top job, and in December IBM &lt;a href=&quot;https://to.fiveminute.cloud/lzdNJT&quot;&gt;joined up&lt;/a&gt; with Salesforce to integrate IBM’s Digital Health Pass with Salesforce for COVID-19 screening. Salesforce continued the march and &lt;a href=&quot;https://to.fiveminute.cloud/6NK6Nv&quot;&gt;launched&lt;/a&gt; Work.com for Vaccines, and added new tools to its Healthcloud including &lt;a href=&quot;https://to.fiveminute.cloud/tITFK1&quot;&gt;Destinations&lt;/a&gt;, its no-code healthcare interoperability solution.&lt;/p&gt;

&lt;p&gt;With Cloud infrastructure spend in Q3 2020 growing by 33% to US$36.5B, coupled with the ongoing COVID-19 pandemic, I think it’s safe to predict that the big cloud providers will continue to invest heavily in healthcare. It also gives them access to a treasure-trove of valuable data ripe for exploitation through the democratization of machine leaning.&lt;/p&gt;

&lt;h3 id=&quot;prediction-3--there-will-be-an-expansion-of-mental-health-initiatives-to-combat-a-global-pandemic&quot;&gt;Prediction 3 – There will be an expansion of mental health initiatives to combat a global pandemic.&lt;/h3&gt;
&lt;p&gt;During 2020, SAP launched its Mental Health initiative, and Accenture &lt;a href=&quot;https://to.fiveminute.cloud/jvaRLc&quot;&gt;found&lt;/a&gt; that 81 percent of people who talked about their mental health at work reported reduced stress levels and increased productivity. DXC joined forces with the UK NHS Service and &lt;a href=&quot;https://to.fiveminute.cloud/sshLPc&quot;&gt;revolutionized&lt;/a&gt; mental health services with its Open Health Connect platform.  In December the &lt;a href=&quot;https://to.fiveminute.cloud/Xoe8gK&quot;&gt;Lancet&lt;/a&gt; stated “People with depressive, anxiety, or obsessive-compulsive disorders are experiencing a detrimental impact on their mental health from the COVID-19 pandemic, which requires close monitoring in clinical practice”.&lt;/p&gt;

&lt;p&gt;With the UK government announcing a third lockdown today, I think it’s safe to predict an increasing demand for mental health services during 2021.  The BMA &lt;a href=&quot;https://to.fiveminute.cloud/lB6pt9&quot;&gt;found&lt;/a&gt; in September the mental health workforce has grown little over the past 10 years, and that the five-year forward view for a mental health workforce is not on track. The workforce challenges aren’t going to be fixed overnight, and I hope technology can help readdress the balance with new solutions to address loneliness, social isolation and build communities. Perhaps technologies like virtual reality will be reborn allowing us to travel beyond our homes.&lt;/p&gt;

&lt;h3 id=&quot;prediction-4--we-will-have-a-national-health-defense-system-for-insights-integration&quot;&gt;Prediction 4 – We will have a National Health Defense System for Insights Integration.&lt;/h3&gt;
&lt;p&gt;Like so many, I have become an armchair expert in analysing government datasets. I’ve noticed it takes a woefully long time to see data aggregated from across the nations.  Even today, COVID statistics are skewed on Mondays and Tuesdays – Monday is often lower because of data lag over the weekend, Tuesdays is often higher because it’s playing catchup.  That means data is not accurate for at least two days a week.  Back in March 2020 the UK was plunged into lockdown because the hospitals were reaching capacity.  Now, in January 2021, we’re told that hospital admissions are 40% higher than in March. Does that mean, capacity is now at 140%?  I think I need to phone a friend for that one.  In September, the UK Government pointed the finger at Microsoft Excel for misplacing 16,000 COVID test results.&lt;/p&gt;

&lt;p&gt;Everyone is doing their very best in a difficult time, and it highlights to me a growing need for a ‘national health defense system’ akin to a military surveillance system.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;We need data that is accurate and timely at a national level so it can be acted upon at a local level.
&lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The insights gleaned from real-time surveillance will help better care planning and take a step towards a national alert system.  Alerts will be used to avoid national lockdowns and return to some level of normality.&lt;/p&gt;

&lt;p&gt;And this leads me onto my final prediction.&lt;/p&gt;

&lt;h3 id=&quot;prediction-5---ai-for-care-logistics&quot;&gt;Prediction 5 - AI for Care Logistics.&lt;/h3&gt;
&lt;p&gt;My final prediction is a little unorthodox.  It’s hard to escape the ongoing impact of the global pandemic, and the detrimental impact it is having on the smooth operation of hospital networks.   The BMJ &lt;a href=&quot;https://to.fiveminute.cloud/BL2R8V&quot;&gt;announced&lt;/a&gt; in September that waiting times in England have reached record highs with an 81-fold increase in patients waiting more than a year.  In 2021 AC there will be a new class of AI and machine learning focussing on care logistics. We will learn to more accurately predict the length of stay, forecast extended stays, avoid capacity problems, optimise staff rosters, implement skills matching and smart resource allocation.  Perhaps we will even build ‘marketplaces’ where patients can be matched to spare capacity across extended hospital networks. &lt;a href=&quot;https://to.fiveminute.cloud/4oUNmc&quot;&gt;Analysis&lt;/a&gt; by the Health Foundation showed there were 4.7 million fewer referrals for routine hospital care for things like hip, knee and cataract surgery during 2020.  It will take time to work through this enormous backlog, and perhaps AI and machine learning can help with the burdensome task of care planning and logistics.&lt;/p&gt;</content><author><name>Pete Wood</name><email>pete@fiveminute.cloud</email></author><category term="healthcare" /><category term="cloud" /><summary type="html">Today is a momentous occasion. At 7.30GMT, the retired maintenance manager Brian Pinker, 82, became the first patient to receive the Oxford-AstraZeneca vaccine. The first vaccine that doesn’t require super-cold storage. The ‘2020 BC epoch’, as I like to call it (Before-COVID), showed how predictions are often wildly inaccurate, and subject to different realities yet to be imagined. But, in a 2021 AC era (After-COVID), with vaccines being rolled out across the UK, I feel confident enough to make a few predictions about what the rest of 2021 has install for us. My only disclaimer is these are my thoughts, and I reserve the right to change them. But, perhaps, just perhaps, you might be bold enough to wager a few Bitcoins that I might indeed be right. Bitcoin is currently trading at a record high of $33,562 so my first prediction is it will only go down. Sorry about that. But with that disclaimer out of the way, here are my top ideas for 2021 AC.</summary></entry></feed>